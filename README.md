# GAI (Graphic Agent Interface)

MCPê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” ì„œë¹„ìŠ¤ë„ ì—ì´ì „íŠ¸ê°€ ì´ìš© ê°€ëŠ¥í•˜ë„ë¡ ì—ì´ì „íŠ¸ì™€ GUI ê°„ì˜ ì—°ë™ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

## Features

- ğŸ¤– **Agentic AI**: ììœ¨ ì—ì´ì „íŠ¸ ê¸°ëŠ¥
- ğŸ”Œ **Multi-LLM Support**: Anthropic (Claude), OpenAI, Google Gemini, Ollama ì§€ì›
- ğŸšï¸ **Smart Mode Selection**: ì‘ì—…ì— ë”°ë¥¸ LLM ìë™ ì„ íƒ (ê¸°ë³¸ / ë¹ ë¥¸ / ë¹„ì „)
- ğŸ› ï¸ **Tool Calling**: LLM native tool callingìœ¼ë¡œ GUI ìë™í™”
- ğŸ’‰ **Dependency Injection**: GUI íˆ´ì´ LLMì„ ì£¼ì…ë°›ì•„ Vision API í™œìš©
- ğŸ¯ **Modular**: í…”ë ˆê·¸ë¨ ëª¨ë“ˆ ì„ íƒì  ë¹Œë“œ ê°€ëŠ¥
- âš™ï¸ **ENV-based Config**: í™˜ê²½ë³€ìˆ˜ ìš°ì„  ì„¤ì • ì‹œìŠ¤í…œ

## Quick Start

### 1. Installation

```bash
npm install
```

### 2. Configuration

í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •:

```bash
# .env íŒŒì¼ ìƒì„±
cp config/.env.example config/.env

# .env íŒŒì¼ í¸ì§‘
nano config/.env
```

```.env
# API Keys
ANTHROPIC_API_KEY=sk-ant-xxx
OPENAI_API_KEY=sk-xxx
GOOGLE_API_KEY=xxx
OLLAMA_BASE_URL=http://localhost:11434

# LLM (DEFAULT í•„ìˆ˜, FAST/VISION ì„ íƒ)
DEFAULT_PROVIDER=ollama
DEFAULT_MODEL=gpt-oss:120b
DEFAULT_MAX_TOKENS=8096
DEFAULT_TEMPERATURE=0.7

FAST_PROVIDER=ollama
FAST_MODEL=gpt-oss:20b
FAST_MAX_TOKENS=4096
FAST_TEMPERATURE=0.5

VISION_PROVIDER=ollama
VISION_MODEL=qwen2.5vl:32b
VISION_MAX_TOKENS=8096
VISION_TEMPERATURE=0.7

# Agent
AGENT_MAX_ITERATIONS=10

# Telegram
TELEGRAM_ENABLED=false
TELEGRAM_BOT_TOKEN=xxx
```

### 3. Run

```bash
# ê°œë°œ ëª¨ë“œ (ëŒ€í™”í˜•)
npm run dev

# í”„ë¡œë•ì…˜ ë¹Œë“œ í›„ ì‹¤í–‰
npm run build
npm start
```

## Architecture

```
CLI / Telegram Bot
    â†“
Agent (ì¶”ë¡  ë£¨í”„)
    â†“
LLM Manager
    â”œâ”€ Mode Selection (default/fast/vision)
    â””â”€ Providers (Anthropic | OpenAI | Google | Ollama)
        â””â”€ Provider-native History Management
    â†“
Tool Registry â†’ GUI Tools | Built-in Tools
```

**í•µì‹¬ ì„¤ê³„:**
- **DI Pattern**: GUI íˆ´ì´ LLM ì¸ìŠ¤í„´ìŠ¤ ì£¼ì…ë°›ì•„ ì‚¬ìš©
- **Provider-native History**: ê° LLMì´ ìì²´ íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- **ENV-first Config**: í™˜ê²½ë³€ìˆ˜ê°€ ìµœìš°ì„ , fallback ì§€ì›
- **Plugin System**: ìƒˆë¡œìš´ íˆ´ì„ ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥

## Current Status

âœ… **Implemented**:
- Core type definitions
- **LLM provider system (ALL)**:
  - âœ… Anthropic (Claude)
  - âœ… OpenAI (GPT)
  - âœ… Google (Gemini)
  - âœ… Ollama (Local models)
- Provider-native history management
- Tool system with DI
- Agent core (agentic loop)
- ENV-based configuration system
- CLI interface
- Mode selection (default/fast/vision)

ğŸš§ **TODO**:
- GUI íˆ´ ì‹¤ì œ êµ¬í˜„ (í™”ë©´ ìº¡ì²˜, í´ë¦­, ì…ë ¥)
- í…”ë ˆê·¸ë¨ ëª¨ë“ˆ
- ë²¡í„° DB ì—°ë™

## LLM Mode System

ì‘ì—…ì— ë”°ë¼ ì ì ˆí•œ LLMì„ ì„ íƒí•˜ì—¬ ë¹„ìš©ê³¼ ì„±ëŠ¥ì„ ìµœì í™”:

### ğŸ¯ Default Mode (ê¸°ë³¸ ëª¨ë¸)
- **ìš©ë„**: ë³µì¡í•œ ì¶”ë¡ , ì½”ë“œ ìƒì„±, ê¹Šì€ ë¶„ì„
- **ì˜ˆì‹œ ëª¨ë¸**: Claude Opus, GPT-4, Gemini Pro
- **ì‚¬ìš© ì¼€ì´ìŠ¤**: ì•„í‚¤í…ì²˜ ì„¤ê³„, ë²„ê·¸ ë¶„ì„, ë³µì¡í•œ ë¡œì§ êµ¬í˜„

### âš¡ Fast Mode (ë¹ ë¥¸ ëª¨ë¸)
- **ìš©ë„**: ë¹ ë¥¸ ì‘ë‹µ, ë‹¨ìˆœ ì‘ì—…, ë¹„ìš© ì ˆê°
- **ì˜ˆì‹œ ëª¨ë¸**: Claude Haiku, GPT-3.5, Llama 3 (local)
- **ì‚¬ìš© ì¼€ì´ìŠ¤**: í…ìŠ¤íŠ¸ ìš”ì•½, ê°„ë‹¨í•œ ì§ˆë¬¸ ì‘ë‹µ, ë°ì´í„° ì¶”ì¶œ

### ğŸ‘ï¸ Vision Mode (ë¹„ì „ ëª¨ë¸)
- **ìš©ë„**: í™”ë©´ ìº¡ì²˜ ë¶„ì„, UI ìš”ì†Œ ì¸ì‹
- **ì˜ˆì‹œ ëª¨ë¸**: Claude Sonnet (Vision), GPT-4 Vision, Gemini Vision
- **ì‚¬ìš© ì¼€ì´ìŠ¤**: í™”ë©´ ì´í•´, GUI ìë™í™”, ì´ë¯¸ì§€ ê¸°ë°˜ ì‘ì—…

## Configuration

### ENV ìš°ì„ ìˆœìœ„

1. **í™˜ê²½ë³€ìˆ˜** (.env íŒŒì¼ ë˜ëŠ” ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜) - ìµœìš°ì„ 
2. **JSON ì„¤ì • íŒŒì¼** (config/config.json) - fallback
3. **ê¸°ë³¸ê°’** (ì½”ë“œ ë‚´ë¶€) - ë§ˆì§€ë§‰ fallback

### Fallback ì‹œìŠ¤í…œ

FAST/VISION ëª¨ë“œê°€ ì„¤ì •ë˜ì§€ ì•Šìœ¼ë©´ DEFAULT ì‚¬ìš©:

```env
# DEFAULTë§Œ ì„¤ì • â†’ ëª¨ë“  ëª¨ë“œì—ì„œ DEFAULT ì‚¬ìš©
DEFAULT_PROVIDER=ollama
DEFAULT_MODEL=gpt-oss:120b
DEFAULT_MAX_TOKENS=8096
DEFAULT_TEMPERATURE=0.7

# FAST ì¶”ê°€ ì„¤ì • â†’ FASTëŠ” 20b ì‚¬ìš©, VISIONì€ DEFAULT ì‚¬ìš©
FAST_PROVIDER=ollama
FAST_MODEL=gpt-oss:20b
FAST_MAX_TOKENS=4096
FAST_TEMPERATURE=0.5
```

### ì§€ì› ëª¨ë¸

#### Anthropic (2026-02 ìµœì‹ )
- claude-opus-4 (ê°€ì¥ ê°•ë ¥, multimodal)
- claude-sonnet-4.5 (ê· í˜•ì¡íŒ ì„±ëŠ¥, multimodal)
- claude-haiku-4.5 (ë¹ ë¥´ê³  ì €ë ´, multimodal)

#### OpenAI (2026-02 ìµœì‹ )
- gpt-5.2 (ê°€ì¥ ê°•ë ¥)
- gpt-4.1 (ê³ ì„±ëŠ¥)
- o4-mini (ì¶”ë¡  íŠ¹í™”)

#### Google (2026-02 ìµœì‹ )
- gemini-3-pro-preview (ê°€ì¥ ê°•ë ¥, multimodal, 1M tokens)
- gemini-3-flash-preview (ë¹ ë¥´ê³  ê°•ë ¥, multimodal, 1M tokens)
- gemini-2.5-pro (ì•ˆì • ë²„ì „, multimodal)

#### Ollama (ë¡œì»¬)
- ëª¨ë“  Ollama ì§€ì› ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥

## Example Usage

```bash
# ëŒ€í™”í˜• ëª¨ë“œë¡œ ì‹¤í–‰
npm start

# ì‹¤í–‰ í›„ í”„ë¡¬í”„íŠ¸ì—ì„œ ë©”ì‹œì§€ ì…ë ¥
> Echo hello world
> Analyze the current screen
```

## Development

```bash
# ê°œë°œ ëª¨ë“œ (tsxë¡œ ì¦‰ì‹œ ì‹¤í–‰)
npm run dev

# ë¹Œë“œ
npm run build

# ë¹Œë“œëœ íŒŒì¼ ì‹¤í–‰
npm start
```

## License

MIT License
